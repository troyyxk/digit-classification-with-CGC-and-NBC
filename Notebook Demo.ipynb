{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter main\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-562373435660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-562373435660>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter main\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mean_mles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/yxk/Documents/github/digit-classification-with-CGC-and-NBC/data.pyc\u001b[0m in \u001b[0;36mload_all_data\u001b[0;34m(data_dir, shuffle)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_STEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_STEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/yxk/Documents/github/digit-classification-with-CGC-and-NBC/data.pyc\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir, stem)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mdigit_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yxk/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yxk/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yxk/.local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfloatconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Question 2.1 Skeleton Code\n",
    "\n",
    "Here you should implement and evaluate the Conditional Gaussian classifier.\n",
    "'''\n",
    "\n",
    "import data\n",
    "import numpy as np\n",
    "# Import pyplot - plt.imshow is useful!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_mean_mles(train_data, train_labels):\n",
    "    '''\n",
    "    Compute the mean estimate for each digit class\n",
    "\n",
    "    Should return a numpy array of size (10,64)\n",
    "    The ith row will correspond to the mean estimate for digit class i\n",
    "    '''\n",
    "    means = []\n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        # print(i_digits.shape)\n",
    "        i_digits_mean = np.mean(i_digits, axis=0)\n",
    "        means.append(i_digits_mean)\n",
    "\n",
    "    return np.array(means)\n",
    "\n",
    "def compute_sigma_mles(train_data, train_labels):\n",
    "    all = []\n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        all.append(np.cov(i_digits.T))\n",
    "\n",
    "    return np.array(all)\n",
    "\n",
    "\n",
    "# def compute_sigma_mles(train_data, train_labels):\n",
    "#     '''\n",
    "#     Compute the covariance estimate for each digit class\n",
    "\n",
    "#     Should return a three dimensional numpy array of shape (10, 64, 64)\n",
    "#     consisting of a covariance matrix for each digit class \n",
    "#     '''\n",
    "\n",
    "\n",
    "#     covariances = []\n",
    "    \n",
    "#     means = compute_mean_mles(train_data, train_labels)\n",
    "    \n",
    "#     for i in range(10):\n",
    "#         i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "#         i_mean = means[i]\n",
    "#         diff_matrices = []\n",
    "#         for j in range(int(i_digits.shape[0])):\n",
    "#             diff = i_digits[i] - i_mean\n",
    "#             m_diff = diff[np.newaxis]\n",
    "#             diff_matrices.append(m_diff.T.dot(m_diff))\n",
    "#         covariances.append(np.mean(np.array(diff_matrices), axis=0))\n",
    "\n",
    "#     stabilizer = 0.01*np.identity(64)\n",
    "\n",
    "#     for i in range(10):\n",
    "#         covariances[i] = covariances[i]+stabilizer\n",
    "\n",
    "#     covariances = np.array(covariances)\n",
    "\n",
    "#     # Compute covariances\n",
    "#     return covariances\n",
    "\n",
    "def plot_cov_diagonal(covariances):\n",
    "    # Plot the log-diagonal of each covariance matrix side by side\n",
    "    all_num = []\n",
    "    for i in range(10):\n",
    "        cov_diag = np.diag(covariances[i])\n",
    "        all_num.append(np.log(cov_diag).reshape(8,8))\n",
    "\n",
    "    all_concat = np.concatenate(all_num, 1)\n",
    "    plt.imshow(all_concat, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def generative_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the generative log-likelihood:\n",
    "        log p(x|y,mu,Sigma)\n",
    "\n",
    "    Should return an n x 10 numpy array \n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def conditional_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the conditional likelihood:\n",
    "\n",
    "        log p(y|x, mu, Sigma)\n",
    "\n",
    "    This should be a numpy array of shape (n, 10)\n",
    "    Where n is the number of datapoints and 10 corresponds to each digit class\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def avg_conditional_likelihood(digits, labels, means, covariances):\n",
    "    '''\n",
    "    Compute the average conditional likelihood over the true class labels\n",
    "\n",
    "        AVG( log p(y_i|x_i, mu, Sigma) )\n",
    "\n",
    "    i.e. the average log likelihood that the model assigns to the correct class label\n",
    "    '''\n",
    "    cond_likelihood = conditional_likelihood(digits, means, covariances)\n",
    "\n",
    "    # Compute as described above and return\n",
    "    return None\n",
    "\n",
    "def classify_data(digits, means, covariances):\n",
    "    '''\n",
    "    Classify new points by taking the most likely posterior class\n",
    "    '''\n",
    "    cond_likelihood = conditional_likelihood(digits, means, covariances)\n",
    "    # Compute and return the most likely class\n",
    "    pass\n",
    "\n",
    "def main():\n",
    "    print(\"Enter main\")\n",
    "    train_data, train_labels, test_data, test_labels = data.load_all_data('data')\n",
    "    # Fit the model\n",
    "    means = compute_mean_mles(train_data, train_labels)\n",
    "    covariances = compute_sigma_mles(train_data, train_labels)\n",
    "    # a = tmp(train_data, train_labels)\n",
    "    # b = np_cov(train_data, train_labels)\n",
    "    plot_cov_diagonal(covariances)\n",
    "    \n",
    "    # Evaluation\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter main\n",
      "[[[ 0.01112687  0.00132789  0.00075437 ...  0.00086621  0.00090676\n",
      "    0.00053317]\n",
      "  [ 0.00132789  0.02037976  0.01431108 ...  0.00800593  0.00341418\n",
      "    0.00094626]\n",
      "  [ 0.00075437  0.01431108  0.05321287 ...  0.02297475  0.00814242\n",
      "    0.00123227]\n",
      "  ...\n",
      "  [ 0.00086621  0.00800593  0.02297475 ...  0.05931961  0.01847093\n",
      "    0.00234618]\n",
      "  [ 0.00090676  0.00341418  0.00814242 ...  0.01847093  0.02306039\n",
      "    0.00303943]\n",
      "  [ 0.00053317  0.00094626  0.00123227 ...  0.00234618  0.00303943\n",
      "    0.01159803]]\n",
      "\n",
      " [[ 0.01636434  0.01431464  0.00862436 ...  0.0099977   0.01157995\n",
      "    0.00423428]\n",
      "  [ 0.01431464  0.05744437  0.04192573 ...  0.04002026  0.03714161\n",
      "    0.01081989]\n",
      "  [ 0.00862436  0.04192573  0.06584498 ...  0.04771423  0.03505016\n",
      "    0.00767949]\n",
      "  ...\n",
      "  [ 0.0099977   0.04002026  0.04771423 ...  0.06942188  0.04333733\n",
      "    0.00897156]\n",
      "  [ 0.01157995  0.03714161  0.03505016 ...  0.04333733  0.05389185\n",
      "    0.01237489]\n",
      "  [ 0.00423428  0.01081989  0.00767949 ...  0.00897156  0.01237489\n",
      "    0.015545  ]]\n",
      "\n",
      " [[ 0.02503628  0.01995146  0.01140668 ...  0.00267102  0.00227779\n",
      "    0.00338429]\n",
      "  [ 0.01995146  0.06412311  0.04631047 ...  0.00687781  0.00736829\n",
      "    0.00823053]\n",
      "  [ 0.01140668  0.04631047  0.08786659 ...  0.00742977  0.00851163\n",
      "    0.00867909]\n",
      "  ...\n",
      "  [ 0.00267102  0.00687781  0.00742977 ...  0.07397738  0.04068178\n",
      "    0.01033933]\n",
      "  [ 0.00227779  0.00736829  0.00851163 ...  0.04068178  0.07861424\n",
      "    0.03388035]\n",
      "  [ 0.00338429  0.00823053  0.00867909 ...  0.01033933  0.03388035\n",
      "    0.05074516]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.04900818  0.03945331  0.01766273 ...  0.00451253  0.00559887\n",
      "    0.00350001]\n",
      "  [ 0.03945331  0.08387225  0.04583844 ...  0.00798218  0.00502352\n",
      "    0.00183614]\n",
      "  [ 0.01766273  0.04583844  0.07410588 ...  0.00483091  0.00062734\n",
      "   -0.000852  ]\n",
      "  ...\n",
      "  [ 0.00451253  0.00798218  0.00483091 ...  0.03621953  0.00589991\n",
      "   -0.00100274]\n",
      "  [ 0.00559887  0.00502352  0.00062734 ...  0.00589991  0.0335622\n",
      "    0.00548208]\n",
      "  [ 0.00350001  0.00183614 -0.000852   ... -0.00100274  0.00548208\n",
      "    0.01977606]]\n",
      "\n",
      " [[ 0.01643957  0.01101392  0.00793735 ...  0.0054189   0.00438259\n",
      "    0.00223207]\n",
      "  [ 0.01101392  0.04866213  0.04042482 ...  0.021693    0.01417136\n",
      "    0.00497151]\n",
      "  [ 0.00793735  0.04042482  0.08024978 ...  0.02853766  0.01579458\n",
      "    0.00415265]\n",
      "  ...\n",
      "  [ 0.0054189   0.021693    0.02853766 ...  0.06471768  0.03000296\n",
      "    0.00627814]\n",
      "  [ 0.00438259  0.01417136  0.01579458 ...  0.03000296  0.03743113\n",
      "    0.00848826]\n",
      "  [ 0.00223207  0.00497151  0.00415265 ...  0.00627814  0.00848826\n",
      "    0.01516728]]\n",
      "\n",
      " [[ 0.01127104  0.00275189  0.00174725 ... -0.00012943  0.00068829\n",
      "    0.00158354]\n",
      "  [ 0.00275189  0.02835995  0.02339863 ...  0.00315974  0.00888752\n",
      "    0.00837866]\n",
      "  [ 0.00174725  0.02339863  0.06403214 ...  0.00884624  0.0161721\n",
      "    0.01229321]\n",
      "  ...\n",
      "  [-0.00012943  0.00315974  0.00884624 ...  0.04661734  0.01142995\n",
      "   -0.0021239 ]\n",
      "  [ 0.00068829  0.00888752  0.0161721  ...  0.01142995  0.04977653\n",
      "    0.0129376 ]\n",
      "  [ 0.00158354  0.00837866  0.01229321 ... -0.0021239   0.0129376\n",
      "    0.02920028]]]\n",
      "--------------------------------\n",
      "[[[ 0.00112848  0.00132979  0.00075545 ...  0.00086745  0.00090806\n",
      "    0.00053393]\n",
      "  [ 0.00132979  0.01039461  0.01433155 ...  0.00801738  0.00341906\n",
      "    0.00094761]\n",
      "  [ 0.00075545  0.01433155  0.04327469 ...  0.02300762  0.00815407\n",
      "    0.00123403]\n",
      "  ...\n",
      "  [ 0.00086745  0.00801738  0.02300762 ...  0.04939016  0.01849735\n",
      "    0.00234954]\n",
      "  [ 0.00090806  0.00341906  0.00815407 ...  0.01849735  0.01307907\n",
      "    0.00304378]\n",
      "  [ 0.00053393  0.00094761  0.00123403 ...  0.00234954  0.00304378\n",
      "    0.00160032]]\n",
      "\n",
      " [[ 0.00637344  0.01433512  0.0086367  ...  0.010012    0.01159652\n",
      "    0.00424034]\n",
      "  [ 0.01433512  0.04751225  0.04198571 ...  0.04007751  0.03719475\n",
      "    0.01083537]\n",
      "  [ 0.0086367   0.04198571  0.05592487 ...  0.04778249  0.0351003\n",
      "    0.00769048]\n",
      "  ...\n",
      "  [ 0.010012    0.04007751  0.04778249 ...  0.05950689  0.04339933\n",
      "    0.00898439]\n",
      "  [ 0.01159652  0.03719475  0.0351003  ...  0.04339933  0.04395464\n",
      "    0.0123926 ]\n",
      "  [ 0.00424034  0.01083537  0.00769048 ...  0.00898439  0.0123926\n",
      "    0.00555294]]\n",
      "\n",
      " [[ 0.01505779  0.01998     0.011423   ...  0.00267484  0.00228105\n",
      "    0.00338913]\n",
      "  [ 0.01998     0.05420054  0.04637673 ...  0.00688765  0.00737884\n",
      "    0.00824231]\n",
      "  [ 0.011423    0.04637673  0.07797798 ...  0.0074404   0.00852381\n",
      "    0.0086915 ]\n",
      "  ...\n",
      "  [ 0.00267484  0.00688765  0.0074404  ...  0.06406891  0.04073998\n",
      "    0.01035412]\n",
      "  [ 0.00228105  0.00737884  0.00852381 ...  0.04073998  0.06871241\n",
      "    0.03392882]\n",
      "  [ 0.00338913  0.00824231  0.0086915  ...  0.01035412  0.03392882\n",
      "    0.04080345]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.03906399  0.03950975  0.017688   ...  0.00451899  0.00560688\n",
      "    0.00350501]\n",
      "  [ 0.03950975  0.07397793  0.04590401 ...  0.0079936   0.00503071\n",
      "    0.00183877]\n",
      "  [ 0.017688    0.04590401  0.06419759 ...  0.00483782  0.00062824\n",
      "   -0.00085321]\n",
      "  ...\n",
      "  [ 0.00451899  0.0079936   0.00483782 ...  0.02625704  0.00590835\n",
      "   -0.00100418]\n",
      "  [ 0.00560688  0.00503071  0.00062824 ...  0.00590835  0.02359591\n",
      "    0.00548992]\n",
      "  [ 0.00350501  0.00183877 -0.00085321 ... -0.00100418  0.00548992\n",
      "    0.00979005]]\n",
      "\n",
      " [[ 0.00644878  0.01102968  0.0079487  ...  0.00542666  0.00438886\n",
      "    0.00223527]\n",
      "  [ 0.01102968  0.03871744  0.04048265 ...  0.02172403  0.01419163\n",
      "    0.00497862]\n",
      "  [ 0.0079487   0.04048265  0.07035028 ...  0.02857849  0.01581717\n",
      "    0.0041586 ]\n",
      "  ...\n",
      "  [ 0.00542666  0.02172403  0.02857849 ...  0.05479596  0.03004588\n",
      "    0.00628712]\n",
      "  [ 0.00438886  0.01419163  0.01581717 ...  0.03004588  0.02747038\n",
      "    0.00850041]\n",
      "  [ 0.00223527  0.00497862  0.0041586  ...  0.00628712  0.00850041\n",
      "    0.00517468]]\n",
      "\n",
      " [[ 0.00127286  0.00275583  0.00174975 ... -0.00012961  0.00068927\n",
      "    0.0015858 ]\n",
      "  [ 0.00275583  0.01838622  0.0234321  ...  0.00316426  0.00890023\n",
      "    0.00839065]\n",
      "  [ 0.00174975  0.0234321   0.05410944 ...  0.00885889  0.01619524\n",
      "    0.01231079]\n",
      "  ...\n",
      "  [-0.00012961  0.00316426  0.00885889 ...  0.03666972  0.01144631\n",
      "   -0.00212694]\n",
      "  [ 0.00068927  0.00890023  0.01619524 ...  0.01144631  0.03983344\n",
      "    0.01295611]\n",
      "  [ 0.0015858   0.00839065  0.01231079 ... -0.00212694  0.01295611\n",
      "    0.01922775]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Question 2.1 Skeleton Code\n",
    "\n",
    "Here you should implement and evaluate the Conditional Gaussian classifier.\n",
    "'''\n",
    "\n",
    "import data\n",
    "import numpy as np\n",
    "# Import pyplot - plt.imshow is useful!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_mean_mles(train_data, train_labels):\n",
    "    '''\n",
    "    Compute the mean estimate for each digit class\n",
    "\n",
    "    Should return a numpy array of size (10,64)\n",
    "    The ith row will correspond to the mean estimate for digit class i\n",
    "    '''\n",
    "    means = []\n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        # print(i_digits.shape)\n",
    "        i_digits_mean = np.mean(i_digits, axis=0)\n",
    "        means.append(i_digits_mean)\n",
    "\n",
    "    return np.array(means)\n",
    "\n",
    "def np_cov(train_data, train_labels):\n",
    "    all = []\n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        all.append(np.cov(i_digits.T))\n",
    "\n",
    "    return np.array(all)\n",
    "\n",
    "\n",
    "def tmp(train_data, train_labels):\n",
    "    covariances = np.zeros((10, 64, 64))\n",
    "    \n",
    "    means = compute_mean_mles(train_data, train_labels)\n",
    "    \n",
    "    d = 64\n",
    "    \n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        \n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                var_1 = i_digits[:,j]-means[i,j]\n",
    "                var_2 = i_digits[:,k]-means[i,k]\n",
    "                var = np.mean(var_1*var_2,0)\n",
    "            \n",
    "                covariances[i,j,k] = var\n",
    "                \n",
    "                if j==k:\n",
    "                    covariances[i,j,k]+=0.01\n",
    "            \n",
    "    return covariances\n",
    "\n",
    "    covariances = np.zeros((10, 64, 64))\n",
    "\n",
    "def tmp1(train_data, train_labels):\n",
    "    covariances = np.zeros((10, 64, 64))\n",
    "    \n",
    "    means = compute_mean_mles(train_data, train_labels)\n",
    "    \n",
    "    d = 64\n",
    "    \n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        \n",
    "        for j in range(d):\n",
    "            for k in range(d):\n",
    "                var_1 = i_digits[:,j]-means[i,j]\n",
    "                var_2 = i_digits[:,k]-means[i,k]\n",
    "                var = np.mean(var_1*var_2,0)\n",
    "            \n",
    "                covariances[i,j,k] = var\n",
    "                \n",
    "                if j==k:\n",
    "                    covariances[i,j,k]+=0.01\n",
    "            \n",
    "    return covariances\n",
    "\n",
    "    covariances = np.zeros((10, 64, 64))\n",
    "\n",
    "def compute_sigma_mles(train_data, train_labels):\n",
    "    '''\n",
    "    Compute the covariance estimate for each digit class\n",
    "\n",
    "    Should return a three dimensional numpy array of shape (10, 64, 64)\n",
    "    consisting of a covariance matrix for each digit class \n",
    "    '''\n",
    "\n",
    "\n",
    "    covariances = []\n",
    "    \n",
    "    means = compute_mean_mles(train_data, train_labels)\n",
    "    \n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        i_mean = means[i]\n",
    "        diff_matrices = []\n",
    "        for j in range(int(i_digits.shape[0])):\n",
    "            diff = i_digits[i] - i_mean\n",
    "            m_diff = diff[np.newaxis]\n",
    "            diff_matrices.append(m_diff.T.dot(m_diff))\n",
    "        covariances.append(np.mean(np.array(diff_matrices), axis=0))\n",
    "\n",
    "    stabilizer = 0.01*np.identity(64)\n",
    "\n",
    "    for i in range(10):\n",
    "        covariances[i] = covariances[i]+stabilizer\n",
    "\n",
    "    covariances = np.array(covariances)\n",
    "\n",
    "    # Compute covariances\n",
    "    return covariances\n",
    "\n",
    "def plot_cov_diagonal(covariances):\n",
    "    # Plot the log-diagonal of each covariance matrix side by side\n",
    "    all_num = []\n",
    "    for i in range(10):\n",
    "        cov_diag = np.diag(covariances[i])\n",
    "        all_num.append(np.log(cov_diag).reshape(8,8))\n",
    "\n",
    "    all_concat = np.concatenate(all_num, 1)\n",
    "    plt.imshow(all_concat, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def generative_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the generative log-likelihood:\n",
    "        log p(x|y,mu,Sigma)\n",
    "\n",
    "    Should return an n x 10 numpy array \n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def conditional_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the conditional likelihood:\n",
    "\n",
    "        log p(y|x, mu, Sigma)\n",
    "\n",
    "    This should be a numpy array of shape (n, 10)\n",
    "    Where n is the number of datapoints and 10 corresponds to each digit class\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def avg_conditional_likelihood(digits, labels, means, covariances):\n",
    "    '''\n",
    "    Compute the average conditional likelihood over the true class labels\n",
    "\n",
    "        AVG( log p(y_i|x_i, mu, Sigma) )\n",
    "\n",
    "    i.e. the average log likelihood that the model assigns to the correct class label\n",
    "    '''\n",
    "    cond_likelihood = conditional_likelihood(digits, means, covariances)\n",
    "\n",
    "    # Compute as described above and return\n",
    "    return None\n",
    "\n",
    "def classify_data(digits, means, covariances):\n",
    "    '''\n",
    "    Classify new points by taking the most likely posterior class\n",
    "    '''\n",
    "    cond_likelihood = conditional_likelihood(digits, means, covariances)\n",
    "    # Compute and return the most likely class\n",
    "    pass\n",
    "\n",
    "def main():\n",
    "    print(\"Enter main\")\n",
    "    train_data, train_labels, test_data, test_labels = data.load_all_data('data')\n",
    "    # Fit the model\n",
    "    means = compute_mean_mles(train_data, train_labels)\n",
    "    covariances = compute_sigma_mles(train_data, train_labels)\n",
    "    a = tmp(train_data, train_labels)\n",
    "    b = np_cov(train_data, train_labels)\n",
    "    print(a)\n",
    "    print(\"--------------------------------\")\n",
    "    print(b)\n",
    "    plot_cov_diagonal(b)\n",
    "    \n",
    "    # Evaluation\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter main\n",
      "[[[ 0.00112848  0.00132979  0.00075545 ...  0.00086745  0.00090806\n",
      "    0.00053393]\n",
      "  [ 0.00132979  0.01039461  0.01433155 ...  0.00801738  0.00341906\n",
      "    0.00094761]\n",
      "  [ 0.00075545  0.01433155  0.04327469 ...  0.02300762  0.00815407\n",
      "    0.00123403]\n",
      "  ...\n",
      "  [ 0.00086745  0.00801738  0.02300762 ...  0.04939016  0.01849735\n",
      "    0.00234954]\n",
      "  [ 0.00090806  0.00341906  0.00815407 ...  0.01849735  0.01307907\n",
      "    0.00304378]\n",
      "  [ 0.00053393  0.00094761  0.00123403 ...  0.00234954  0.00304378\n",
      "    0.00160032]]\n",
      "\n",
      " [[ 0.00637344  0.01433512  0.0086367  ...  0.010012    0.01159652\n",
      "    0.00424034]\n",
      "  [ 0.01433512  0.04751225  0.04198571 ...  0.04007751  0.03719475\n",
      "    0.01083537]\n",
      "  [ 0.0086367   0.04198571  0.05592487 ...  0.04778249  0.0351003\n",
      "    0.00769048]\n",
      "  ...\n",
      "  [ 0.010012    0.04007751  0.04778249 ...  0.05950689  0.04339933\n",
      "    0.00898439]\n",
      "  [ 0.01159652  0.03719475  0.0351003  ...  0.04339933  0.04395464\n",
      "    0.0123926 ]\n",
      "  [ 0.00424034  0.01083537  0.00769048 ...  0.00898439  0.0123926\n",
      "    0.00555294]]\n",
      "\n",
      " [[ 0.01505779  0.01998     0.011423   ...  0.00267484  0.00228105\n",
      "    0.00338913]\n",
      "  [ 0.01998     0.05420054  0.04637673 ...  0.00688765  0.00737884\n",
      "    0.00824231]\n",
      "  [ 0.011423    0.04637673  0.07797798 ...  0.0074404   0.00852381\n",
      "    0.0086915 ]\n",
      "  ...\n",
      "  [ 0.00267484  0.00688765  0.0074404  ...  0.06406891  0.04073998\n",
      "    0.01035412]\n",
      "  [ 0.00228105  0.00737884  0.00852381 ...  0.04073998  0.06871241\n",
      "    0.03392882]\n",
      "  [ 0.00338913  0.00824231  0.0086915  ...  0.01035412  0.03392882\n",
      "    0.04080345]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.03906399  0.03950975  0.017688   ...  0.00451899  0.00560688\n",
      "    0.00350501]\n",
      "  [ 0.03950975  0.07397793  0.04590401 ...  0.0079936   0.00503071\n",
      "    0.00183877]\n",
      "  [ 0.017688    0.04590401  0.06419759 ...  0.00483782  0.00062824\n",
      "   -0.00085321]\n",
      "  ...\n",
      "  [ 0.00451899  0.0079936   0.00483782 ...  0.02625704  0.00590835\n",
      "   -0.00100418]\n",
      "  [ 0.00560688  0.00503071  0.00062824 ...  0.00590835  0.02359591\n",
      "    0.00548992]\n",
      "  [ 0.00350501  0.00183877 -0.00085321 ... -0.00100418  0.00548992\n",
      "    0.00979005]]\n",
      "\n",
      " [[ 0.00644878  0.01102968  0.0079487  ...  0.00542666  0.00438886\n",
      "    0.00223527]\n",
      "  [ 0.01102968  0.03871744  0.04048265 ...  0.02172403  0.01419163\n",
      "    0.00497862]\n",
      "  [ 0.0079487   0.04048265  0.07035028 ...  0.02857849  0.01581717\n",
      "    0.0041586 ]\n",
      "  ...\n",
      "  [ 0.00542666  0.02172403  0.02857849 ...  0.05479596  0.03004588\n",
      "    0.00628712]\n",
      "  [ 0.00438886  0.01419163  0.01581717 ...  0.03004588  0.02747038\n",
      "    0.00850041]\n",
      "  [ 0.00223527  0.00497862  0.0041586  ...  0.00628712  0.00850041\n",
      "    0.00517468]]\n",
      "\n",
      " [[ 0.00127286  0.00275583  0.00174975 ... -0.00012961  0.00068927\n",
      "    0.0015858 ]\n",
      "  [ 0.00275583  0.01838622  0.0234321  ...  0.00316426  0.00890023\n",
      "    0.00839065]\n",
      "  [ 0.00174975  0.0234321   0.05410944 ...  0.00885889  0.01619524\n",
      "    0.01231079]\n",
      "  ...\n",
      "  [-0.00012961  0.00316426  0.00885889 ...  0.03666972  0.01144631\n",
      "   -0.00212694]\n",
      "  [ 0.00068927  0.00890023  0.01619524 ...  0.01144631  0.03983344\n",
      "    0.01295611]\n",
      "  [ 0.0015858   0.00839065  0.01231079 ... -0.00212694  0.01295611\n",
      "    0.01922775]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Question 2.1 Skeleton Code\n",
    "\n",
    "Here you should implement and evaluate the Conditional Gaussian classifier.\n",
    "'''\n",
    "\n",
    "import data\n",
    "import numpy as np\n",
    "# Import pyplot - plt.imshow is useful!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_mean_mles(train_data, train_labels):\n",
    "    '''\n",
    "    Compute the mean estimate for each digit class\n",
    "\n",
    "    Should return a numpy array of size (10,64)\n",
    "    The ith row will correspond to the mean estimate for digit class i\n",
    "    '''\n",
    "    means = []\n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        # print(i_digits.shape)\n",
    "        i_digits_mean = np.mean(i_digits, axis=0)\n",
    "        means.append(i_digits_mean)\n",
    "\n",
    "    return np.array(means)\n",
    "\n",
    "def compute_sigma_mles(train_data, train_labels):\n",
    "    all = []\n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        all.append(np.cov(i_digits.T))\n",
    "\n",
    "    return np.array(all)\n",
    "\n",
    "\n",
    "# def compute_sigma_mles(train_data, train_labels):\n",
    "#     '''\n",
    "#     Compute the covariance estimate for each digit class\n",
    "\n",
    "#     Should return a three dimensional numpy array of shape (10, 64, 64)\n",
    "#     consisting of a covariance matrix for each digit class \n",
    "#     '''\n",
    "\n",
    "\n",
    "#     covariances = []\n",
    "    \n",
    "#     means = compute_mean_mles(train_data, train_labels)\n",
    "    \n",
    "#     for i in range(10):\n",
    "#         i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "#         i_mean = means[i]\n",
    "#         diff_matrices = []\n",
    "#         for j in range(int(i_digits.shape[0])):\n",
    "#             diff = i_digits[i] - i_mean\n",
    "#             m_diff = diff[np.newaxis]\n",
    "#             diff_matrices.append(m_diff.T.dot(m_diff))\n",
    "#         covariances.append(np.mean(np.array(diff_matrices), axis=0))\n",
    "\n",
    "#     stabilizer = 0.01*np.identity(64)\n",
    "\n",
    "#     for i in range(10):\n",
    "#         covariances[i] = covariances[i]+stabilizer\n",
    "\n",
    "#     covariances = np.array(covariances)\n",
    "\n",
    "#     # Compute covariances\n",
    "#     return covariances\n",
    "\n",
    "def plot_cov_diagonal(covariances):\n",
    "    # Plot the log-diagonal of each covariance matrix side by side\n",
    "    all_num = []\n",
    "    for i in range(10):\n",
    "        cov_diag = np.diag(covariances[i])\n",
    "        all_num.append(np.log(cov_diag).reshape(8,8))\n",
    "\n",
    "    all_concat = np.concatenate(all_num, 1)\n",
    "    plt.imshow(all_concat, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def generative_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the generative log-likelihood:\n",
    "        log p(x|y,mu,Sigma)\n",
    "\n",
    "    Should return an n x 10 numpy array \n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def conditional_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the conditional likelihood:\n",
    "\n",
    "        log p(y|x, mu, Sigma)\n",
    "\n",
    "    This should be a numpy array of shape (n, 10)\n",
    "    Where n is the number of datapoints and 10 corresponds to each digit class\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "def avg_conditional_likelihood(digits, labels, means, covariances):\n",
    "    '''\n",
    "    Compute the average conditional likelihood over the true class labels\n",
    "\n",
    "        AVG( log p(y_i|x_i, mu, Sigma) )\n",
    "\n",
    "    i.e. the average log likelihood that the model assigns to the correct class label\n",
    "    '''\n",
    "    cond_likelihood = conditional_likelihood(digits, means, covariances)\n",
    "\n",
    "    # Compute as described above and return\n",
    "    return None\n",
    "\n",
    "def classify_data(digits, means, covariances):\n",
    "    '''\n",
    "    Classify new points by taking the most likely posterior class\n",
    "    '''\n",
    "    cond_likelihood = conditional_likelihood(digits, means, covariances)\n",
    "    # Compute and return the most likely class\n",
    "    pass\n",
    "\n",
    "def main():\n",
    "    print(\"Enter main\")\n",
    "    train_data, train_labels, test_data, test_labels = data.load_all_data('data')\n",
    "    # Fit the model\n",
    "    means = compute_mean_mles(train_data, train_labels)\n",
    "    covariances = compute_sigma_mles(train_data, train_labels)\n",
    "    # a = tmp(train_data, train_labels)\n",
    "    # b = np_cov(train_data, train_labels)\n",
    "    print(covariances)\n",
    "    plot_cov_diagonal(covariances)\n",
    "    \n",
    "    # Evaluation\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
